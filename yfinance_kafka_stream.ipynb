{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeJnyHZQHnc9w7qNgueyw0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/irabufan/BZFabricPub/blob/main/yfinance_kafka_stream.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install confluent_kafka"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6ZvUyRa9mpS",
        "outputId": "dae6f563-1523-40ab-b314-28a5fe2af102"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: confluent_kafka in /usr/local/lib/python3.10/dist-packages (2.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EVXr8A264zs",
        "outputId": "2ce76b16-ec56-4160-b5ee-ab7a52a761aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  4 of 4 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  4 of 4 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  4 of 4 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  4 of 4 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  4 of 4 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  4 of 4 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  4 of 4 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  4 of 4 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  4 of 4 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  4 of 4 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  4 of 4 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  4 of 4 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%%**********************]  4 of 4 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from confluent_kafka import Producer\n",
        "import json\n",
        "import yfinance as yf\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "def delivery_report(err, msg):\n",
        "    \"\"\" Called once for each message produced to indicate delivery result.\n",
        "        Triggered by poll() or flush(). \"\"\"\n",
        "    if err is not None:\n",
        "        print('Message delivery failed: {}'.format(err))\n",
        "    else:\n",
        "        print('Message delivered to {} [{}]'.format(msg.topic(), msg.partition()))\n",
        "\n",
        "# Get the Kafka broker address from the environment variable\n",
        "kafka_broker = userdata.get('kafka_broker')\n",
        "username = userdata.get('sasl_username')\n",
        "password = userdata.get('sasl_password')\n",
        "\n",
        "p = Producer({\n",
        "    'bootstrap.servers': kafka_broker,\n",
        "    'sasl.mechanisms': 'PLAIN',\n",
        "    'security.protocol': 'SASL_SSL',\n",
        "    'sasl.username': username,\n",
        "    'sasl.password': password\n",
        "})\n",
        "\n",
        "# Define the symbols and the Kafka topic\n",
        "symbols = [\"EURUSD=X\",\"USDJPY=X\",\"USDHKD=X\",\"JPYEUR=X\"]\n",
        "topic = userdata.get('kafka_topic')\n",
        "\n",
        "# Initialize an empty DataFrame to store the previous data\n",
        "prev_data = None\n",
        "# Initialize a count variable to set how many times to execute\n",
        "rcount = 0\n",
        "\n",
        "while rcount < 30:\n",
        "    # Download the latest market data\n",
        "    data = yf.download(symbols, period=\"1d\", interval=\"1m\")\n",
        "\n",
        "    # Stack and sort the data, and remove rows with missing 'Open' prices\n",
        "    out = data.stack().reset_index(level=1, names=[\"\", \"Ticker\"]).sort_values(by=\"Ticker\").reset_index(level=0)\n",
        "    out = out.dropna(subset=['Open']).sort_values(['Datetime'], ascending=[False], key=lambda s: s.astype(\"string\") if s.name in ['Datetime'] else s).rename(columns={'Adj Close': 'AdjClose'})\n",
        "    # only select top 5 rows for each ticker for performance\n",
        "    out = out.groupby(\"Ticker\").head(5)\n",
        "\n",
        "    # Compare the new results with the prior download\n",
        "    if prev_data is not None:\n",
        "        # Get the latest timestamp in the previous data\n",
        "        latest_timestamp = prev_data['Datetime'].max()\n",
        "\n",
        "        # Keep only the new data that has a later timestamp\n",
        "        new_data = out[out['Datetime'] > latest_timestamp]\n",
        "\n",
        "        if not new_data.empty:\n",
        "            # Convert the new results to JSON\n",
        "            out_json = new_data.to_json(orient='records', date_format=\"iso\")\n",
        "\n",
        "            # Send the JSON message to the Kafka topic\n",
        "            p.produce(topic, out_json)\n",
        "            p.flush()\n",
        "\n",
        "    else:\n",
        "        # On initial run, just send the latest record available per Ticker\n",
        "        new_data = out.groupby(\"Ticker\").head(1)\n",
        "\n",
        "        if not new_data.empty:\n",
        "            # Convert the new results to JSON\n",
        "            out_json = new_data.to_json(orient='records', date_format=\"iso\")\n",
        "\n",
        "            # Send the JSON message to the Kafka topic\n",
        "            p.produce(topic, out_json)\n",
        "            p.flush()\n",
        "\n",
        "    # Update the previous data\n",
        "    prev_data = out.copy()\n",
        "\n",
        "    rcount +=1\n",
        "    print(rcount)\n",
        "\n",
        "    # Wait for a while before the next iteration\n",
        "    time.sleep(60)\n"
      ]
    }
  ]
}